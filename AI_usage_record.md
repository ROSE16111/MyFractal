Openai-chatgpt5
* Q1
COMP3710_Lab_1_v.2.0.pdf
Prompt: I am going to use Newton Fractal to do this task, what should I do now. These are the files that I already made. å…·ä½“æ­¥éª¤è¯¦ç»†è§£é‡Šï¼Œä¸­æ–‡ä¸ºä¸»ï¼Œå…³é”®è¯ç”¨è‹±æ–‡æ ‡æ³¨ã€‚å§‹ç»ˆæŒ‰æ–‡ä»¶è¦æ±‚æ¥
   
Answer:

å¾ˆå¥½ï¼ä½ å·²ç»å†³å®šåš Newton Fractalï¼Œè€Œä¸”å·²æœ‰ NewtonFractal.pyã€README.mdã€AI_usage_record.docx çš„é›å½¢ã€‚ä¸‹é¢æˆ‘ç»™ä½ ä¸€å¥—æŒ‰å®éªŒæ–‡ä»¶è¦æ±‚ï¼ˆTasks/Important Notes/Demonstrationï¼‰æ¥è½åœ°çš„æ­¥éª¤ + å¯ç›´æ¥ç”¨çš„ä»£ç éª¨æ¶ä¸æ–‡æ¡£æ¨¡æ¿ã€‚ä¸­æ–‡ä¸ºä¸»ã€å…³é”®æœ¯è¯­ç”¨ Englishã€‚

ä½ è¦åšçš„äº‹ï¼ˆæŒ‰è¦æ±‚å¯¹é½ï¼‰

å»ºä»“åº“ & ç»„ç»‡ç»“æ„ï¼ˆRepository structureï¼‰

æŒ‰å®éªŒè¦æ±‚ï¼Œæ–°å»ºä¸€ä¸ªç‹¬ç«‹ä»“åº“å¹¶æŠŠä»£ç  push ä¸Šå»ï¼Œæ¼”ç¤ºæ—¶è¦èƒ½åœ¨ GitHub é¡µé¢çœ‹åˆ°ã€‚

å»ºè®®ç»“æ„ï¼š

MyFractal/
â”œâ”€ src/
â”‚  â””â”€ NewtonFractal.py
â”œâ”€ analysis/
â”‚  â””â”€ box_counting.py           # ç»´æ•°ä¼°è®¡
â”œâ”€ outputs/                     # ç”Ÿæˆçš„å›¾ç‰‡/åˆ†æå›¾
â”œâ”€ docs/
â”‚  â”œâ”€ AI_usage_record.md        # è®°å½• prompts å’Œä¿®æ”¹
â”‚  â””â”€ references.md             # å¯é€‰
â”œâ”€ README.md
â””â”€ requirements.txt


ä¸ºä»€ä¹ˆè¦è¿™æ ·ï¼šä»“åº“è¦æ¸…æ¥šå±•ç¤ºå¹¶è¡Œå®ç° + é¢å¤–åˆ†æ + AI ä½¿ç”¨è®°å½•ï¼Œæ»¡è¶³â€œImportant Notesâ€å’Œâ€œDemonstrationâ€çš„è¯„åˆ†ç‚¹ã€‚
 

å®ç° Newton Fractalï¼ˆPyTorch/GPUï¼Œvectorised + maskï¼‰

è¦ç‚¹ï¼šä¸»è¦ç®—æ³•ç¯èŠ‚åœ¨ PyTorch/TF ä¸Šå¹¶è¡Œï¼ˆparallelismï¼‰ï¼Œæ¼”ç¤ºæ—¶è¦èƒ½è¯´æ˜ã€‚

ä¸‹é¢ç»™ä½  src/NewtonFractal.py çš„å‚è€ƒå®ç°ï¼ˆå¯ç›´æ¥æ›¿æ¢/è¡¥å…¨ä½ å·²æœ‰çš„æ–‡ä»¶ï¼‰ï¼š

# src/NewtonFractal.py
import numpy as np
import torch
import matplotlib.pyplot as plt

# ---------------------------
# 0) Device & dtype
# ---------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.set_default_dtype(torch.float32)
complex_dtype = torch.complex64
print("Device:", device)

# ---------------------------
# 1) Build complex grid (vectorised on GPU)
# ---------------------------
def build_grid(x_range=(-2.0, 2.0), y_range=(-2.0, 2.0), step=0.0025):
    y_np, x_np = np.mgrid[y_range[0]:y_range[1]:step, x_range[0]:x_range[1]:step]
    x = torch.from_numpy(x_np).to(device=device)
    y = torch.from_numpy(y_np).to(device=device)
    grid = torch.complex(x, y).to(dtype=complex_dtype)
    return grid

# ---------------------------
# 2) Newton iteration for f(z) = z^3 - 1
# roots: 1, -1/2 Â± i*sqrt(3)/2
# ---------------------------
ROOTS = torch.tensor(
    [1.0 + 0.0j,
     -0.5 + np.sqrt(3)/2*1j,
     -0.5 - np.sqrt(3)/2*1j],
    dtype=complex_dtype, device=device
)

def newton_fractal(x_range=(-2,2), y_range=(-2,2), step=0.0025,
                   max_iter=50, tol=1e-6):
    """
    Vectorised Newton fractal on GPU.
    Returns:
      root_idx (H,W,int8): æ”¶æ•›åˆ°å“ªä¸ªæ ¹ï¼ˆ-1 è¡¨ç¤ºæœªæ”¶æ•›ï¼‰
      iters    (H,W,int16): æ”¶æ•›æ‰€éœ€æ­¥æ•°ï¼ˆæˆ–åˆ°è¾¾ä¸Šé™ï¼‰
    """
    z = build_grid(x_range, y_range, step)   # z0
    H, W = z.shape

    root_idx = torch.full((H, W), -1, dtype=torch.int8, device=device)   # basin label
    iters    = torch.zeros((H, W), dtype=torch.int16, device=device)     # steps to converge
    mask     = torch.ones((H, W), dtype=torch.bool, device=device)       # still not converged

    with torch.no_grad():
        for k in range(max_iter):
            if not mask.any(): break

            z_alive = z[mask]

            # f(z) = z^3 - 1, f'(z) = 3 z^2
            f  = z_alive*z_alive*z_alive - 1.0
            fp = 3.0 * z_alive*z_alive

            # é¿å…é™¤é›¶ï¼šåŠ ä¸€ä¸ªå° epsilon
            z_alive = z_alive - f / (fp + 1e-12)

            # å†™å›
            z[mask] = z_alive

            # æ”¶æ•›åˆ¤æ®ï¼šè·ç¦»ä»»ä¸€æ ¹ < tol  æˆ– |f(z)| < tol
            # å…ˆå¯¹æ¯ä¸ªåƒç´ åˆ†åˆ«è®¡ç®—åˆ°ä¸‰ä¸ªæ ¹çš„è·ç¦»ï¼Œé€‰æœ€è¿‘çš„
            diffs = z_alive.unsqueeze(-1) - ROOTS  # shape: (N_alive, 3)
            d2 = (diffs.real**2 + diffs.imag**2)
            min_d2, min_idx = torch.min(d2, dim=1)

            # ä»ç„¶åœ¨æ´»è·ƒé›†åˆé‡Œçš„åƒç´ çš„å…¨å±€ä½ç½®
            # æ ¹æ® min_d2 < tol^2 æ ‡è®°æ”¶æ•›
            conv = (min_d2 < (tol*tol))
            # ç»™åˆšæ”¶æ•›çš„åƒç´ å†™å…¥æ ¹ç¼–å·ä¸è¿­ä»£æ­¥æ•°
            root_idx[mask] = torch.where(conv, min_idx.to(torch.int8), root_idx[mask])
            iters[mask]    = torch.where(conv, torch.tensor(k+1, dtype=torch.int16, device=device), iters[mask])

            # æ›´æ–°æ´»è·ƒé®ç½©ï¼šæœªæ”¶æ•›çš„ç»§ç»­è¿­ä»£
            alive_indices = torch.where(mask)
            new_mask = mask.clone()
            new_mask[alive_indices[0][conv], alive_indices[1][conv]] = False
            mask = new_mask

    return root_idx.detach().cpu().numpy(), iters.detach().cpu().numpy()

# ---------------------------
# 3) Colouring / Visualisation
# ---------------------------
def color_root_basins(root_idx, iters, gamma=0.75):
    """
    æ ¹åŸŸç€è‰²ï¼ˆbasins of attractionï¼‰+ è¿­ä»£æ­¥æ•°åšäº®åº¦ï¼šsteps^{-gamma}
    """
    idx = root_idx.copy()
    H, W = idx.shape
    img = np.zeros((H, W, 3), dtype=np.float32)

    # ä¸‰ä¸ªæ ¹çš„åŸºè‰²
    colors = np.array([[0.9, 0.2, 0.2],
                       [0.2, 0.9, 0.2],
                       [0.2, 0.2, 0.9]], dtype=np.float32)

    for i in range(3):
        mask = (idx == i)
        shade = (iters[mask] + 1e-3)**(-gamma)   # æ­¥æ•°è¶Šå°‘è¶Šäº®
        img[mask] = colors[i] * shade[:, None]

    # æœªæ”¶æ•›ï¼ˆ-1ï¼‰æ¶‚é»‘
    img[idx < 0] = 0.0
    return np.uint8(np.clip(img*255, 0, 255))

# ---------------------------
# 4) Demo run
# ---------------------------
if __name__ == "__main__":
    root_idx, iters = newton_fractal(
        x_range=(-2.0, 2.0), y_range=(-2.0, 2.0),
        step=0.0025, max_iter=50, tol=1e-6
    )

    img = color_root_basins(root_idx, iters, gamma=0.75)
    plt.figure(figsize=(10, 10))
    plt.imshow(img)
    plt.axis("off")
    plt.tight_layout(pad=0)
    # plt.savefig("outputs/newton.png", dpi=200)  # ä¿å­˜
    plt.show()


æ¼”ç¤ºè¦ç‚¹ï¼ˆtalking pointsï¼‰ï¼švectorised on GPUï¼ˆæ•´å¼ ç½‘æ ¼å¼ é‡å¹¶è¡Œæ›´æ–°ï¼‰ã€maskï¼ˆåªè¿­ä»£æœªæ”¶æ•›åƒç´ ã€å¯æå‰åœæ­¢ï¼‰ã€no gradï¼ˆæ¨ç†æ¨¡å¼ï¼‰ã€root basinsï¼ˆæŒ‰æ ¹ç€è‰² + é€Ÿåº¦æ˜æš—ï¼‰ã€‚è¿™æ­£å¥½å¯¹åº”â€œä¸»è¦ç»„ä»¶ä½¿ç”¨ PyTorch/TF å¹¶è¡Œâ€çš„è€ƒæ ¸ç‚¹ï¼ˆ3 åˆ†ï¼‰ã€‚

åšâ€œå®è´¨æ€§åˆ†æâ€ï¼ˆsubstantial analysisï¼‰
æ–‡æ¡£è¦æ±‚ï¼šå¦‚æœä½¿ç”¨ AI ç”Ÿæˆä»£ç /å›¾ï¼Œä½ å¿…é¡»è®°å½• promptsï¼Œå¹¶é¢å¤–åšå®è´¨æ€§åˆ†æï¼Œæ¯”å¦‚ä¼°è®¡åˆ†å½¢ç»´æ•°ï¼ˆfractal dimensionï¼‰æˆ–åšä¸åŒå¯è§†åŒ–/é…è‰²ã€‚

æ¨èåš Box-counting çš„â€œè¾¹ç•Œç»´æ•°â€ä¼°è®¡ï¼šå¯¹æ ¹åŸŸè¾¹ç•ŒåšäºŒå€¼åŒ–ï¼Œå†å¤šå°ºåº¦ç½‘æ ¼è®¡æ•°å¹¶æ‹Ÿåˆæ–œç‡ã€‚ä¸‹é¢ç»™ analysis/box_counting.pyï¼ˆç›´æ¥å¯ç”¨ï¼‰ï¼š

# analysis/box_counting.py
import numpy as np
import matplotlib.pyplot as plt

def boundary_mask(root_idx: np.ndarray) -> np.ndarray:
    """
    ä»æ ¹ç¼–å·å›¾ä¸­æå–â€œè¾¹ç•Œåƒç´ â€ï¼š
    é‚»åŸŸ(4-æˆ–8-è¿é€š)ä¸­è‹¥å­˜åœ¨ä¸åŒæ ¹ç¼–å·ï¼Œåˆ™è¯¥åƒç´ åœ¨è¾¹ç•Œä¸Šã€‚
    """
    H, W = root_idx.shape
    m = np.zeros((H, W), dtype=bool)
    for dy in (-1, 0, 1):
        for dx in (-1, 0, 1):
            if dx == 0 and dy == 0: continue
            nb = np.roll(np.roll(root_idx, dy, axis=0), dx, axis=1)
            m |= (nb != root_idx)
    m[root_idx < 0] = False  # æœªæ”¶æ•›åƒç´ æ’é™¤
    return m

def box_count(mask: np.ndarray, scales=(1,2,4,8,16,32,64)):
    """
    å¯¹äºŒå€¼è¾¹ç•Œ mask åš box-countingã€‚
    è¿”å›æ¯ä¸ª box å°ºå¯¸ s çš„éç©º box æ•° N(s)ã€‚
    """
    H, W = mask.shape
    Ns = []
    for s in scales:
        # ä»¥ sÃ—s ä¸ºæ­¥é•¿åˆ†å—ï¼Œç»Ÿè®¡æ¯å—æ˜¯å¦æœ‰ True
        Hs = (H + s - 1) // s
        Ws = (W + s - 1) // s
        count = 0
        for i in range(Hs):
            for j in range(Ws):
                block = mask[i*s:(i+1)*s, j*s:(j+1)*s]
                if block.any():
                    count += 1
        Ns.append(count)
    return np.array(Ns)

def estimate_dimension(scales, Ns):
    """
    ç”¨ log N(s) ä¸ log(1/s) çº¿æ€§æ‹Ÿåˆæ–œç‡ï¼Œè¿‘ä¼¼è¾¹ç•Œçš„ box-count ç»´æ•°ã€‚
    """
    s = np.array(scales, dtype=float)
    x = np.log(1.0/s)
    y = np.log(Ns + 1e-12)
    k, b = np.polyfit(x, y, 1)
    return k, (x, y)

if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šè¯»å– src è¿è¡Œæ—¶ä¿å­˜çš„ root_idx & iters (ä½ ä¹Ÿå¯ä»¥ç”¨ npy æ–‡ä»¶è¯»å†™)
    # è¿™é‡Œå‡è®¾ä½ åœ¨ NewtonFractal.py é‡Œ np.save è¿‡ root_idx.npy
    root_idx = np.load("outputs/root_idx.npy")  # è‡ªè¡Œä¿å­˜åå†è¿è¡Œæœ¬è„šæœ¬
    mask = boundary_mask(root_idx)
    scales = (1,2,4,8,16,32,64)
    Ns = box_count(mask, scales)
    D, (x, y) = estimate_dimension(scales, Ns)
    print("Estimated box-counting dimension â‰ˆ", D)

    # å¯è§†åŒ–
    plt.figure(figsize=(12,4))
    plt.subplot(1,2,1)
    plt.title("Boundary mask")
    plt.imshow(mask, cmap="gray")
    plt.axis("off")
    plt.subplot(1,2,2)
    plt.title("log N vs log(1/s)")
    plt.plot(x, y, "o-")
    plt.xlabel("log(1/s)")
    plt.ylabel("log N")
    plt.tight_layout()
    plt.show()


è¿™æ ·ä½ å°±æ»¡è¶³â€œsubstantial analysisï¼ˆç»´æ•°ä¼°è®¡ï¼‰æˆ– different visualisationsâ€çš„ç¡¬æ€§è¦æ±‚ä¹‹ä¸€ï¼›ä¹Ÿå»ºè®®é¡ºæ‰‹åšä¸€å¼ â€œä¸åŒé…è‰²/å¯è§†åŒ–â€çš„å¹¶æ’å›¾ï¼ŒåŠ ç¨³å¦¥ã€‚

è®°å½• AI ä½¿ç”¨ï¼ˆprompts & reasoningï¼‰

åœ¨ docs/AI_usage_record.md é‡Œè®°å½•ï¼šæ¯æ¬¡ promptã€æ¨¡å‹äº§å‡ºç‰‡æ®µã€ä½ ä¿®æ”¹äº†å“ªäº›ç‚¹ï¼ˆå¹¶è¡Œ/è®¾å¤‡/é®ç½©/å®¹é”™/é˜ˆå€¼/é…è‰²ï¼‰ã€ä¸ºä»€ä¹ˆä¿®æ”¹ã€‚å•ä¸€ prompt ç›´æ¥å‡ºæœ€ç»ˆç»“æœä¼šè¢«æ‰£åˆ†ã€‚

æ¨¡æ¿ï¼ˆç²˜åˆ° docs/AI_usage_record.mdï¼‰ï¼š

# AI Usage Record

## Prompt 1
- Prompt:
- Model output (key parts):
- My modifications & reasons:

## Prompt 2
...


README.md å¡«å†™ï¼ˆæŒ‰è¯„åˆ†ç‚¹ï¼‰

åŒ…å«ï¼šé¡¹ç›®ç®€ä»‹ï¼ˆNewton Fractal ç®€è¿°ï¼‰ã€è¿è¡Œæ–¹æ³•ï¼ˆå‘½ä»¤å‚æ•°ï¼‰ã€ä¾èµ–ã€å¦‚ä½•å¤ç°å›¾ç‰‡ã€å¹¶è¡Œç‚¹è¯´æ˜ï¼ˆPyTorch tensor + GPU, masking, no_gradï¼‰ã€åˆ†æç»“æœï¼ˆç»´æ•°ä¼°è®¡å›¾/æ•°å€¼ï¼‰ã€AI ä½¿ç”¨è®°å½•ä½ç½®ã€‚

è¿™æ˜¯æ¼”ç¤º 3â€“5 åˆ†é’Ÿé‡Œè¦è®²çš„ä¸»ææ–™ï¼Œè¯„åˆ†é¡¹ I/II/III/IV éƒ½ç”¨å¾—åˆ°ã€‚

Push åˆ° GitHubï¼ˆä¸€å®šè¦èƒ½æ‰“å¼€ä»“åº“é¡µé¢ï¼‰

åˆå§‹åŒ–å¹¶æäº¤ï¼š

git init
git add .
git commit -m "Newton Fractal: GPU vectorised + box-counting analysis"
git branch -M main
git remote add origin <your_repo_url>
git push -u origin main


æ¼”ç¤ºæ—¶éœ€è¦â€œæ˜¾ç¤º GitHub ä»“åº“é¡µé¢ + è¯æ˜æ˜¯ä½ æœ¬äººè´¦å·â€ã€‚

Demoï¼ˆ3â€“5 åˆ†é’Ÿï¼‰æ€ä¹ˆè®²

å±•ç¤ºä»£ç  + è¾“å‡ºï¼šè¯´æ˜ä¸»è¦è®¡ç®—åœ¨ GPU ä¸Šå¹¶è¡Œï¼ˆvectorised ops, mask, no_gradï¼‰ã€‚

å±•ç¤ºä»“åº“ï¼šæ‰“å¼€ä½ çš„ GitHub ä»“åº“ä¸»é¡µã€‚

å›ç­”é—®é¢˜ï¼šç®—æ³•åŸç†ï¼ˆNewton è¿­ä»£ã€æ ¹åŸŸï¼‰ã€æ•°å€¼ç»†èŠ‚ï¼ˆtolã€max_iterã€é™¤é›¶å¤„ç†ï¼‰ã€å·¥ç¨‹ç»†èŠ‚ï¼ˆå¼ é‡æ”¾ GPUã€é®ç½©åŠ é€Ÿã€æå‰é€€å‡ºï¼‰ã€AI ä½¿ç”¨ä¸ä¿®æ”¹ã€‚è¯„åˆ†ç‚¹è§ rubricã€‚

ä½ ç°æœ‰æ–‡ä»¶å¦‚ä½•è½ä½ï¼ˆå¯¹ç…§ä½ çš„æˆªå›¾ï¼‰

æŠŠ MyFractal/NewtonFractal.py ç§»åˆ° src/NewtonFractal.pyï¼Œå¹¶æŒ‰ä¸Šé¢çš„å®ç°è¡¥å…¨ã€‚

README.mdï¼šæŒ‰ä¸Šé¢çš„è¦ç‚¹å®Œå–„ï¼ˆè¿è¡Œæ–¹æ³• + åˆ†æç»“æœ + AI è®°å½•è·¯å¾„ï¼‰ã€‚

AI_usage_record.docx å»ºè®®æ”¹æˆ mdï¼ˆAI_usage_record.mdï¼‰ï¼Œä¾¿äºç‰ˆæœ¬å¯¹æ¯”ä¸åœ¨çº¿é˜…è¯»ã€‚

æ–°å¢ analysis/box_counting.py ä¸ outputs/ æ–‡ä»¶å¤¹ï¼›åœ¨ NewtonFractal.py é‡Œé¢å¤–ä¿å­˜ä¸­é—´ç»“æœï¼ˆå¦‚ np.save("outputs/root_idx.npy", root_idx)ï¼‰ï¼Œä¾¿äºåˆ†æè„šæœ¬è¯»å–ã€‚

requirements.txt å†™ä¸Šï¼š

torch
numpy
matplotlib

å°è´´å£«ï¼ˆé¿å…ä¸¢åˆ†ï¼‰

é€‰æ‹©ï¼šNewton Fractal ä¸ Mandelbrot å·®åˆ«è¶³å¤Ÿå¤§ï¼Œç¬¦åˆâ€œä¸æ¥è¿‘ Mandelbrotâ€çš„è¦æ±‚ã€‚

AI ä½¿ç”¨ï¼šä¸€å®šè®°å½•å¤šè½® prompts ä¸ä½ ä¸»åŠ¨ä¿®æ”¹çš„è¯æ®ã€‚
 

å¹¶è¡Œç‚¹ï¼šå¼ºè°ƒä½ çš„ä¸»è¦è®¡ç®—æ˜¯å¼ é‡åŒ–åœ¨ GPU ä¸Šè¿›è¡Œï¼ˆè€Œéä»…ç”¨å®ƒç”»å›¾ï¼‰ã€‚

åˆ†æï¼šè‡³å°‘åšä¸€ä¸ªâ€œç»´æ•°ä¼°è®¡â€æˆ–â€œå¤šç§å¯è§†åŒ–/é…è‰²â€çš„åŠ é¡¹ï¼ˆæœ€å¥½éƒ½åšï¼‰ã€‚

éœ€è¦çš„è¯æˆ‘å¯ä»¥æŠŠ NewtonFractal.py å†åŠ ä¸Šå¯è§†åŒ–å¯¹æ¯”ï¼ˆroot basins vs. iteration heatmapï¼‰å’Œä¿å­˜ root_idx/iters çš„ .npy è¡Œï¼Œæˆ–è€…ç›´æ¥ç»™ä½ ä¸€ç‰ˆ README.md æ¨¡æ¿æ–‡æœ¬ï¼Œä½ è´´è¿›å»å°±èƒ½äº¤

* Q2
P:
vectorised on GPUï¼ˆæ•´å¼ ç½‘æ ¼å¼ é‡å¹¶è¡Œæ›´æ–°ï¼‰ã€maskï¼ˆåªè¿­ä»£æœªæ”¶æ•›åƒç´ ã€å¯æå‰åœæ­¢ï¼‰ã€no gradï¼ˆæ¨ç†æ¨¡å¼ï¼‰ã€root basinsï¼ˆæŒ‰æ ¹ç€è‰² + é€Ÿåº¦æ˜æš—ï¼‰ã€‚è¯¦ç»†åˆ†æä¸€ä¸‹è¿™å››ä¸ªç‚¹å¯¹åº”äº†å“ªäº›ä»£ç ï¼Œç„¶åå‘Šè¯‰æˆ‘å“ªé‡Œä½“ç°å‡ºä¸»è¦ç»„ä»¶ä½¿ç”¨ PyTorch/TF å¹¶è¡Œï¼Œä¸»è¦ç»„ä»¶ä½¿ç”¨ PyTorch/TF å¹¶è¡Œæ˜¯ä»€ä¹ˆæ„æ€
A:
å¥½å˜ï¼æˆ‘æŠŠä½ å…³å¿ƒçš„ 4 ä¸ªå…³é”®è¯é€ä¸€â€œå¯¹å·å…¥åº§â€ï¼Œæ ‡å‡ºå¯¹åº”çš„ä»£ç ã€è§£é‡Šâ€œåœ¨åšä»€ä¹ˆ/ä¸ºä»€ä¹ˆè¿™ä¹ˆåšâ€ï¼Œæœ€åè®²æ¸…æ¥šä»€ä¹ˆå«ä¸»è¦ç»„ä»¶ä½¿ç”¨ PyTorch/TF å¹¶è¡Œä»¥åŠä½ åœ¨ä»£ç é‡Œå¦‚ä½•è¯æ˜è¿™ä¸€ç‚¹ã€‚

1) vectorised on GPUï¼ˆæ•´å¼ ç½‘æ ¼å¼ é‡å¹¶è¡Œæ›´æ–°ï¼‰
ä»£ç ä½ç½®ï¼ˆç¤ºä¾‹æ¥è‡ªæˆ‘ç»™ä½ çš„ NewtonFractal.pyï¼‰
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
...
x = torch.from_numpy(x_np).to(device=device)
y = torch.from_numpy(y_np).to(device=device)
grid = torch.complex(x, y).to(dtype=complex_dtype)      # (H,W) å¤æ•°ç½‘æ ¼ï¼Œå…¨åœ¨ GPU

# è¿­ä»£æ ¸å¿ƒï¼ˆæ¯ä¸€è½®éƒ½â€œæ•´å¼ å›¾â€å¹¶è¡Œæ›´æ–°ï¼‰
z_alive = z[mask]
c_alive = c[mask]
# (1) f(z)=z^3-1, f'(z)=3z^2   â€”â€” å…¨åœ¨ GPU åšå¼ é‡è¿ç®—
f  = z_alive*z_alive*z_alive - 1.0
fp = 3.0 * z_alive*z_alive
# (2) ç‰›é¡¿æ­¥ z â† z - f/f'
z_alive = z_alive - f / (fp + 1e-12)
z[mask] = z_alive

# (3) ä¸ä¸‰ä¸ªæ ¹åšâ€œå¹¿æ’­â€è·ç¦»æ¯”è¾ƒï¼ˆä¸€æ¬¡æ€§å‘é‡åŒ–ï¼‰
diffs = z_alive.unsqueeze(-1) - ROOTS        # shape: (N_alive, 3)
d2 = (diffs.real**2 + diffs.imag**2)
min_d2, min_idx = torch.min(d2, dim=1)       # reduction åœ¨ GPU ä¸Šåš

è¿™åœ¨å¹²å˜›

vectorisedï¼šæ²¡æœ‰ç”¨ Python çš„åŒé‡ for é€åƒç´ ç®—ï¼Œè€Œæ˜¯æŠŠæ•´å¼  (HÃ—W) ç½‘æ ¼ä½œä¸ºä¸€ä¸ª/å‡ ä¸ªå¤§å¼ é‡äº¤ç»™ PyTorch çš„ CUDA kernels å»ç®—ã€‚

æ¯ä¸ªè¡¨è¾¾å¼ï¼ˆæ¯”å¦‚ z_alive*z_aliveã€torch.minï¼‰éƒ½ä¼šåœ¨ GPU ä¸Šå¯åŠ¨æˆåƒä¸Šä¸‡çš„çº¿ç¨‹ï¼Œä¸€æ¬¡æŠŠæ‰€æœ‰åƒç´ éƒ½æ›´æ–°ã€‚

å¹¿æ’­ï¼ˆbroadcastingï¼‰ï¼šz_alive.unsqueeze(-1) - ROOTS è‡ªåŠ¨æŠŠ (N_alive,1) å’Œ (3,) æ‰©æˆ (N_alive,3)ï¼Œé¿å…æ˜¾å¼å¾ªç¯ã€‚

2) maskï¼ˆåªè¿­ä»£æœªæ”¶æ•›åƒç´ ã€å¯æå‰åœæ­¢ï¼‰
ä»£ç ä½ç½®
mask     = torch.ones((H, W), dtype=torch.bool, device=device)  # ä»æœªæ”¶æ•›(Alive)
...
# åªå¯¹ Alive çš„åƒç´ åšç‰›é¡¿æ­¥
z_alive = z[mask]
c_alive = c[mask]
z_alive = z_alive*z_alive*z_alive - 1.0  # ç­‰ç­‰ï¼ˆç•¥ï¼‰
...
# æ”¶æ•›åˆ¤æ®ï¼šç¦»æŸä¸ªæ ¹è¶³å¤Ÿè¿‘
conv = (min_d2 < (tol*tol))

# æŠŠåˆšæ”¶æ•›çš„åƒç´ ä» mask é‡Œå‰”é™¤ï¼ˆä»¥åä¸å†æ›´æ–°ï¼‰
alive_indices = torch.where(mask)
new_mask = mask.clone()
new_mask[alive_indices[0][conv], alive_indices[1][conv]] = False
mask = new_mask

if not mask.any():    # æ²¡æœ‰æ´»ç€çš„åƒç´ äº† â†’ æå‰ç»“æŸ
    break

è¿™åœ¨å¹²å˜›

ç›®çš„ï¼šå‡å°‘æ— è°“è®¡ç®—ã€åŠ é€Ÿã€‚å·²ç»æ”¶æ•›çš„åƒç´ ä¹‹åæ¯ä¸€è½®éƒ½ä¸ä¼šå†ç®—ï¼ˆå¦åˆ™ç™½ç™½åšä¹˜æ³•/é™¤æ³•ï¼‰ã€‚

åªæ›´æ–° Aliveï¼šz[mask] = ... è¡¨ç¤ºæ›´æ–°çš„æ˜¯å¸ƒå°”ç´¢å¼•é€‰å‡ºæ¥çš„å­é›†ï¼ˆä»æœªæ”¶æ•›çš„åƒç´ é›†åˆï¼‰ã€‚

æå‰ç»“æŸï¼šå½“ mask.any()==Falseï¼Œè¯´æ˜æ‰€æœ‰åƒç´ éƒ½å·²æ”¶æ•›ï¼Œå¾ªç¯ç«‹å³ breakã€‚

å®é™…æ•ˆæœï¼šæ›´å°‘çš„å…ƒç´ å‚ä¸åç»­ CUDA è®¡ç®—ï¼Œæ·±è¿­ä»£/å¤§å›¾æ—¶èƒ½æ˜¾è‘—æé€Ÿã€‚

3) no gradï¼ˆæ¨ç†æ¨¡å¼ / å…³é—­è‡ªåŠ¨æ±‚å¯¼ï¼‰
ä»£ç ä½ç½®
with torch.no_grad():
    for k in range(max_iter):
        ...

è¿™åœ¨å¹²å˜›

åˆ†å½¢æ¸²æŸ“ä¸æ˜¯è®­ç»ƒï¼Œä¸éœ€è¦åå‘ä¼ æ’­çš„ æ¢¯åº¦å›¾ï¼ˆcomputation graphï¼‰ã€‚

torch.no_grad() ä¼šåœ¨è¿™æ®µä»£ç å†…å…³é—­ autogradï¼š

å‡å°‘å†…å­˜ï¼ˆä¸ä¿å­˜ä¸­é—´å˜é‡ï¼‰

å‡å°‘è°ƒåº¦/å…ƒæ“ä½œå¼€é”€

å°å¹…æå‡ååï¼ˆå°¤å…¶åœ¨é«˜è¿­ä»£æ—¶æ›´æ˜æ˜¾ï¼‰

4) root basinsï¼ˆæŒ‰æ ¹ç€è‰² + é€Ÿåº¦æ˜æš—ï¼‰
ä»£ç ä½ç½®
# è®¡ç®—é˜¶æ®µå¾—åˆ°ï¼š
root_idx  # (H,W,int8)  æ¯ä¸ªåƒç´ æ”¶æ•›åˆ°å“ªä¸ªæ ¹ï¼ˆ0/1/2ï¼Œæˆ– -1 = æœªæ”¶æ•›ï¼‰
iters     # (H,W,int16) æ”¶æ•›ç”¨çš„æ­¥æ•°ï¼ˆé€Ÿåº¦ï¼‰

def color_root_basins(root_idx, iters, gamma=0.75):
    colors = np.array([[0.9,0.2,0.2],
                       [0.2,0.9,0.2],
                       [0.2,0.2,0.9]])
    for i in range(3):
        mask = (root_idx == i)
        shade = (iters[mask] + 1e-3)**(-gamma)  # æ­¥æ•°è¶Šå°‘è¶Šäº®ï¼ˆæ”¶æ•›è¶Šå¿«è¶Šäº®ï¼‰
        img[mask] = colors[i] * shade[:, None]
    img[root_idx < 0] = 0.0                     # æœªæ”¶æ•›æ¶‚é»‘

è¿™åœ¨å¹²å˜›

basins of attractionï¼šä¸åŒåˆå€¼ç‚¹æœ€ç»ˆä¼šæ”¶æ•›åˆ°ä¸åŒçš„æ ¹ï¼ˆå¸å¼•åŸŸï¼‰ã€‚

ç”¨ root_idx å†³å®šåŸºè‰²ï¼ˆçº¢/ç»¿/è“ï¼‰ï¼Œç”¨ iters å†³å®šäº®åº¦ï¼ˆæ”¶æ•›æ›´å¿« â†’ æ›´äº®ï¼‰ã€‚

æœªæ”¶æ•›ï¼ˆ-1ï¼‰åƒç´ è®¾ä¸ºé»‘è‰²ï¼Œæ¸…æ™°åŒºåˆ†ã€‚

æ³¨æ„ï¼šè¿™ä¸€æ­¥å¯åœ¨ CPU/NumPy ä¸Šåšï¼ˆå› ä¸ºåªæ˜¯å¯è§†åŒ–ï¼‰ï¼Œä¸»è¦è®¡ç®—å·²åœ¨ GPU å®Œæˆã€‚

â€œä¸»è¦ç»„ä»¶ä½¿ç”¨ PyTorch/TF å¹¶è¡Œâ€æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ

å®šä¹‰ï¼ˆè¯¾å ‚è¯­å¢ƒï¼‰ï¼šä½ çš„åˆ†å½¢ç®—æ³•çš„**æ ¸å¿ƒè®¡ç®—éƒ¨åˆ†ï¼ˆmajor componentï¼‰**å¿…é¡»ä»¥ tensor operations çš„æ–¹å¼äº¤ç»™ PyTorch/TF åç«¯åœ¨ GPUï¼ˆæˆ–ä¼˜åŒ–çš„ CPUï¼‰ä¸Šå¹¶è¡Œæ‰§è¡Œï¼Œè€Œä¸æ˜¯ç”¨ Python è‡ªå·±çš„ for å¾ªç¯é€åƒç´ è®¡ç®—ã€‚

åœ¨ä½ çš„å®ç°é‡Œï¼Œå“ªäº›æ˜¯â€œä¸»è¦ç»„ä»¶å¹¶è¡Œâ€ï¼Ÿ

ä¸»è¦ç»„ä»¶ = Newton è¿­ä»£æ›´æ–° + æ”¶æ•›åˆ¤å®šï¼š

f=z^3-1ã€fp=3z^2ã€z â† z - f/f'ã€ä¸ä¸‰æ ¹çš„è·ç¦»æ¯”è¾ƒ torch.minï¼Œéƒ½æ˜¯å¯¹æ•´å—å¼ é‡çš„å‘é‡åŒ–æ“ä½œã€‚

è¿™äº›æ“ä½œåœ¨ device=cuda çš„å¼ é‡ä¸Šè¿è¡Œ â†’ ç”± CUDA kernels å¯åŠ¨å¤§é‡çº¿ç¨‹åŒæ—¶å¤„ç†æˆåƒä¸Šä¸‡åƒç´ ã€‚

mask ç­–ç•¥ï¼šç”¨å¸ƒå°”å¼ é‡æ¥ç­›é€‰â€œä»æœªæ”¶æ•›â€çš„å…ƒç´ ï¼Œä¿è¯åç»­è®¡ç®—åªåœ¨å¿…è¦çš„å…ƒç´ ä¸Šè¿›è¡Œã€‚è¿™åŒæ ·æ˜¯å¼ é‡çº§å¹¶è¡Œï¼Œè€Œé Python å±‚é¢è¿­ä»£ã€‚

åä¾‹ï¼ˆä¸åˆæ ¼çš„åšæ³•ï¼‰

ç”¨åŒé‡ for y in range(H): for x in range(W): ç„¶åå¯¹æ¯ä¸ªåƒç´ å•ç‹¬åš complex è¿­ä»£ï¼ˆå“ªæ€•å¼ é‡åœ¨ GPU ä¸Šï¼Œä¹Ÿä¼šå›  Python å¾ªç¯ä¸²è¡Œè°ƒç”¨è€Œææ…¢ï¼‰ï¼Œè¿™å°±ä¸æ˜¯â€œä¸»è¦ç»„ä»¶ä½¿ç”¨ PyTorch/TF å¹¶è¡Œâ€ã€‚

å¦‚ä½•ç°åœºè¯æ˜ä½ ç¡®å®åœ¨ç”¨å¹¶è¡Œï¼Ÿ

æ‰“å°/å±•ç¤ºå…³é”®å¼ é‡çš„ deviceï¼šprint(z.device, f.device, root_idx.device) â†’ å…¨æ˜¯ cuda:0ã€‚

å¯¹æ¯”å…³æ‰ GPUï¼ˆå¼ºåˆ¶ device='cpu'ï¼‰çš„è€—æ—¶å·®å¼‚ï¼›æˆ–ç”¨æ›´å¤§çš„å›¾/æ›´å¤§çš„ max_iter æ˜¾ç¤º GPU æ˜æ˜¾æ›´å¿«ã€‚

è®²æ¸…æ¥šï¼š

â€œæˆ‘æ²¡æœ‰é€åƒç´  for å¾ªç¯ï¼›è€Œæ˜¯æŠŠæ•´å¼ å›¾è¡¨ç¤ºä¸ºå¼ é‡ï¼Œæ‰€æœ‰æ›´æ–°éƒ½æ˜¯ element-wise + broadcasting + reductionï¼Œè¿™äº›éƒ½ä¼šè§¦å‘ GPU kernel å¹¶è¡Œæ‰§è¡Œã€‚â€

å°æŠ„ï¼šä¸€å¥è¯è®²æ¸…å››ç‚¹ï¼ˆDemo ç”¨ï¼‰

vectorised on GPUï¼šç½‘æ ¼ä¸çŠ¶æ€ z éƒ½æ˜¯ GPU å¼ é‡ï¼›z*z / f(z) / min ç­‰æ“ä½œä¸€æ¬¡åœ¨æ•´å¼ å›¾ä¸Šåšï¼Œåº•å±‚æ˜¯ CUDA å¹¶è¡Œ kernelã€‚

maskï¼šç”¨å¸ƒå°”å¼ é‡ç­›é€‰æœªæ”¶æ•›åƒç´ ï¼Œåªæ›´æ–°è¿™äº›ç‚¹å¹¶åœ¨å…¨éƒ¨æ”¶æ•›æ—¶æå‰é€€å‡ºï¼Œå‡å°‘æ— è°“è®¡ç®—ã€‚

no gradï¼šç”¨ torch.no_grad() ç¦æ­¢æ„å›¾ï¼Œçœå†…å­˜å’Œå¼€é”€ï¼Œé€‚åˆæ¨ç†æ¸²æŸ“ã€‚

root basinsï¼šè¾“å‡º root_idxï¼ˆå±è°çš„å¸å¼•åŸŸï¼‰+ itersï¼ˆæ”¶æ•›é€Ÿåº¦ï¼‰ï¼ŒæŒ‰æ ¹ä¸Šè‰²ã€æŒ‰é€Ÿåº¦è°ƒäº®åº¦ï¼›æœªæ”¶æ•›æ¶‚é»‘ã€‚

å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥æŠŠä½ çš„ NewtonFractal.py å†åŠ ä¸Šè®¡æ—¶æ‰“å°ï¼ˆGPU/CPU å¯¹æ¯”ï¼‰ã€z.device æ£€æŸ¥ï¼Œå¸®ä½ åœ¨æ¼”ç¤ºæ—¶æ›´æœ‰è¯´æœåŠ›ã€‚

* Q3
P:
ä¼°è®¡åˆ†å½¢ç»´æ•°ï¼ˆfractal dimensionï¼‰æˆ–åšä¸åŒå¯è§†åŒ–/é…è‰²æ˜¯ä¸æ˜¯å¯ä»¥äºŒé€‰ä¸€ï¼Œæˆ‘è§‰å¾—åšä¸åŒå¯è§†åŒ–ä¼šä¸ä¼šæ›´ç®€å•ï¼Œè¯¥å‚æ•°å°±è¡Œï¼Ÿ
A:
ç»“è®ºå…ˆè¯´ï¼š
æ˜¯çš„ï¼Œâ€œä¼°è®¡åˆ†å½¢ç»´æ•°ï¼ˆfractal dimensionï¼‰ æˆ– åšä¸åŒå¯è§†åŒ–/é…è‰²ï¼ˆdifferent visualisations and coloursï¼‰â€æ˜¯äºŒé€‰ä¸€çš„å¯æ¥å—æ–¹å¼ï¼Œç”¨æ¥æ»¡è¶³â€œsubstantial analysisï¼ˆå®è´¨æ€§åˆ†æï¼‰â€çš„è¦æ±‚ã€‚è®²ä¹‰åŸæ–‡å°±æ˜¯â€œfor example â€¦ fractal dimension â€¦ Or incorporate different visualisations and colours â€¦â€ï¼ˆå¼ºè°ƒäº† Orï¼‰ã€‚

ä¸è¿‡â€”â€”å¦‚æœä½ é€‰æ‹©â€œå¯è§†åŒ–è·¯çº¿â€ï¼Œå¿…é¡»åšå¾—æœ‰å®è´¨æ€§ï¼Œä¸èƒ½åªæ˜¯æ¢ä¸€ä¸ª cmap æˆ–æ”¹ä¸€ä¸ªé¢œè‰²å‚æ•°å°±äº†äº‹ï¼›æ•™å­¦å›¢é˜Ÿæœ‰æƒå¯¹â€œæŠ•å…¥ä¸å¤Ÿâ€çš„é¡¹ç›®é™åˆ†ã€‚

ä¸‹é¢ç»™ä½ ä¸€ä»½æœ€ç¨³å¦¥çš„å¯è§†åŒ–æ–¹æ¡ˆï¼ˆNewton Fractal ä¸“ç”¨ï¼‰ï¼Œæ—¢ç®€å•åˆèƒ½ä½“ç°â€œåˆ†ææ·±åº¦â€ï¼Œå¹¶å‘Šè¯‰ä½ è¦æ”¹å“ªå‡ è¡Œä»£ç ã€äº¤ä»˜ä»€ä¹ˆã€‚

é€‰â€œå¯è§†åŒ–è·¯çº¿â€æ€ä¹ˆåšæ‰ç®—â€œå®è´¨æ€§â€ï¼ˆSubstantialï¼‰

å»ºè®®è‡³å°‘åš 3 ç§äº’è¡¥çš„å¯è§†åŒ–ï¼Œå¹¶åœ¨ README é‡Œè§£é‡Šå®ƒä»¬å„è‡ªæ­ç¤ºäº†åˆ†å½¢çš„å“ªä¸ªæ€§è´¨ï¼ˆbasins / speed / boundary ç­‰ï¼‰ï¼š

Root basins mapï¼ˆæ ¹åŸŸå›¾ï¼‰ï¼šä¸åŒæ ¹ç”¨ä¸åŒåŸºè‰²ï¼Œä½“ç°â€œå¸å¼•åŸŸï¼ˆbasin of attractionï¼‰â€çš„åˆ†å‰²ç»“æ„ã€‚

Convergence speed mapï¼ˆæ”¶æ•›é€Ÿåº¦å›¾ï¼‰ï¼šç”¨è¿­ä»£æ­¥æ•° iters åšäº®åº¦/é¢œè‰²ï¼Œå±•ç¤ºå“ªä¸ªåŒºåŸŸæ”¶æ•›å¿«/æ…¢ï¼ˆæ•°å€¼ç¨³å®šæ€§/è¾¹ç•Œåˆšæ€§ï¼‰ã€‚

Residual/phase mapï¼ˆæ®‹å·®æˆ–ç›¸ä½ï¼‰ï¼šå›ºå®šè¿­ä»£æ­¥åç”» log10|f(z)|ï¼ˆæˆ– arg(f(z))ï¼‰ï¼Œæ˜¾ç¤ºâ€œæ”¶æ•›è´¨é‡/å±€éƒ¨åŠ¨åŠ›å­¦â€ï¼›æˆ–å åŠ  boundary mask é«˜äº®è¾¹ç•Œã€‚

åªæ¢ cmap â‰  å®è´¨æ€§ï¼›è€Œæ˜¯è¦æ¢æ•°æ®åº¦é‡ï¼ˆdata metricï¼‰å¹¶è§£é‡Šå«ä¹‰ã€‚è¿™å°±æ»¡è¶³â€œsubstantial analysisâ€çš„ç²¾ç¥ä¸å­—é¢è¦æ±‚ã€‚

ä»£ç æ€ä¹ˆæ”¹ï¼ˆåœ¨ä½ å·²æœ‰ NewtonFractal.py åŸºç¡€ä¸Šï¼‰
1ï¼‰è®©æ ¸å¿ƒå‡½æ•°å¤šè¿”å›ä¸¤ä¸ªé‡

å·²æœ‰ï¼šroot_idx, iters

æ–°å¢ï¼šz_finalï¼ˆæœ€åè¿­ä»£çš„ zï¼‰ï¼Œf_final = z_final**3 - 1ï¼ˆç”¨äºæ®‹å·®/ç›¸ä½ï¼‰

åœ¨è¿­ä»£ç»“æŸååŠ ä¸Šï¼š

# è¿­ä»£å¾ªç¯ç»“æŸåï¼ˆæˆ–è¿”å›å‰ï¼‰
z_final = z.detach().cpu().numpy()
f_final = (z.real*z.real*z.real - 1.0).detach().cpu().numpy()  # æˆ– torch.pow(z,3)-1
return (root_idx.detach().cpu().numpy(),
        iters.detach().cpu().numpy(),
        z_final, f_final)

2ï¼‰ä¸‰ç§å¯è§†åŒ–ï¼ˆæ–°å¢å‡½æ•°æˆ–ç›´æ¥å†™åœ¨ mainï¼‰
import numpy as np
import matplotlib.pyplot as plt

def viz_root_basins(root_idx, iters, gamma=0.75):
    # åŸºäºæ ¹ç¼–å·çš„åŸºè‰² + é€Ÿåº¦è°ƒäº®åº¦ï¼ˆå·²åœ¨ä½ ä»£ç é‡Œæœ‰ç±»ä¼¼å®ç°ï¼‰
    colors = np.array([[0.9,0.2,0.2],
                       [0.2,0.9,0.2],
                       [0.2,0.2,0.9]], dtype=np.float32)
    H, W = root_idx.shape
    img = np.zeros((H,W,3), dtype=np.float32)
    for i in range(3):
        m = (root_idx == i)
        shade = (iters[m] + 1e-3)**(-gamma)
        img[m] = colors[i] * shade[:, None]
    img[root_idx < 0] = 0.0
    return np.uint8(np.clip(img*255, 0, 255))

def viz_speed_heatmap(iters):
    # åªçœ‹â€œè¿­ä»£æ­¥æ•°â€ï¼Œåæ˜ æ”¶æ•›é€Ÿåº¦ï¼ˆæ•°å€¼ç‰¹æ€§ï¼‰
    arr = iters.astype(np.float32)
    arr[arr==0] = np.nan  # æœªæ”¶æ•›æˆ–å¼‚å¸¸å¯è®¾ä¸º NaN åœ¨ cmap é‡Œé€æ˜
    # å½’ä¸€åŒ– & ä¼½é©¬å‹ç¼©ï¼Œå¢å¼ºå¯¹æ¯”åº¦
    m, M = np.nanmin(arr), np.nanmax(arr)
    norm = (arr - m) / (M - m + 1e-9)
    heat = np.uint8(np.clip(255 * (1.0 - norm**0.6), 0, 255))  # å¿«=äº®
    return heat  # å¯ç”¨ plt.imshow(heat, cmap="magma")

def viz_residual_log(f_final):
    # ç”» log10|f(z)|ï¼šæ”¶æ•›è´¨é‡/è¾¹ç•Œé”åº¦ï¼ˆå›ºå®šæ­¥æ•°æˆ–æœ€ç»ˆæ­¥ï¼‰
    mag = np.abs(f_final).astype(np.float32)
    logm = np.log10(mag + 1e-12)
    # çº¿æ€§æ‹‰ä¼¸åˆ° [0,255]
    m, M = np.nanmin(logm), np.nanmax(logm)
    norm = (logm - m) / (M - m + 1e-9)
    return np.uint8(np.clip(255 * (1.0 - norm), 0, 255))  # å°æ®‹å·®=äº®

3ï¼‰ä¸»ç¨‹åºæ¼”ç¤ºï¼ˆå¹¶æ’ä¸‰å›¾ï¼Œç¡®ä¿â€œçœ‹å¾—å‡ºå·®å¼‚â€ï¼‰
root_idx, iters, z_final, f_final = newton_fractal(
    x_range=(-2,2), y_range=(-2,2), step=0.0025, max_iter=50, tol=1e-6
)

img_basins = viz_root_basins(root_idx, iters)
img_speed  = viz_speed_heatmap(iters)
img_resid  = viz_residual_log(f_final)

plt.figure(figsize=(15,5))
plt.subplot(1,3,1); plt.title("Basins + speed"); plt.imshow(img_basins); plt.axis("off")
plt.subplot(1,3,2); plt.title("Convergence steps"); plt.imshow(img_speed, cmap="magma"); plt.axis("off")
plt.subplot(1,3,3); plt.title("log10|f(z)|"); plt.imshow(img_resid, cmap="viridis"); plt.axis("off")
plt.tight_layout(); plt.show()

# ä¿å­˜ï¼ˆç”¨äº READMEï¼‰
# from pathlib import Path; Path("outputs").mkdir(exist_ok=True)
# plt.imsave("outputs/newton_basins.png", img_basins)
# plt.imsave("outputs/newton_steps.png", img_speed, cmap="magma")
# plt.imsave("outputs/newton_residual.png", img_resid, cmap="viridis")


è¿™æ ·ä½ å°±ä¸æ˜¯â€œæ¢ä¸ª cmapâ€ï¼Œè€Œæ˜¯ä¸‰ä¸ªä¸åŒçš„åº¦é‡ç»´åº¦ï¼šbasin åˆ’åˆ†ã€é€Ÿåº¦åœºã€æ®‹å·®/ç›¸ä½ã€‚è¿™åœ¨å£å¤´è§£é‡Šæ—¶ä¹Ÿæ›´â€œåƒåˆ†æâ€ã€‚åŒæ—¶æŠŠå›¾æ”¾è¿› READMEï¼Œå¹¶å†™æ˜ä½ è§‚å¯Ÿåˆ°çš„ç°è±¡ï¼ˆä¾‹å¦‚ï¼šè¾¹ç•Œé™„è¿‘ iters é«˜ã€|f| å¤§å¹…èµ·ä¼ï¼›è¿œç¦»è¾¹ç•Œæ”¶æ•›æ›´å¿«ç­‰ï¼‰ã€‚

README æ€ä¹ˆå†™ï¼ˆç¤ºä¾‹è¦ç‚¹ï¼‰

What we visualiseï¼š

Basins mapï¼šæ˜¾ç¤ºå¸å¼•åŸŸåˆ†å‰²ï¼Œä¸åŒæ ¹ä¸åŒé¢œè‰²ï¼›äº®åº¦æŒ‰æ”¶æ•›æ­¥æ•°ã€‚

Convergence stepsï¼šä»…ç”¨è¿­ä»£æ­¥æ•°ï¼Œç›´è§‚å±•ç¤ºå“ªé‡Œâ€œéš¾æ”¶æ•›â€ã€‚

log10|f(z)|ï¼šæ®‹å·®/å±€éƒ¨åŠ¨åŠ›å­¦ï¼›è¾¹ç•Œå¤„å€¼æ›´å¤§ï¼ˆæˆ–æ›´ä¸å‡åŒ€ï¼‰ã€‚

Why it mattersï¼šè¿™äº›å¯è§†åŒ–â€œè§£é‡Šâ€äº† Newton åŠ¨åŠ›ç³»ç»Ÿçš„ç‰¹å¾ï¼Œè€Œä¸æ˜¯åªæ¢è‰²æ¿ã€‚

How to reproduceï¼šå‘½ä»¤ & å‚æ•°ï¼ˆstep/max_iter/tolï¼‰ã€‚

AI usage recordï¼šé“¾æ¥åˆ° docs/AI_usage_record.mdï¼ˆæ»¡è¶³è®°å½•è¦æ±‚ï¼‰ã€‚

Parallelismï¼šå¼ºè°ƒä¸»è¦è®¡ç®—åœ¨ PyTorch çš„ CUDA tensor ä¸Šå®Œæˆï¼Œä½¿ç”¨ vectorised ops + mask + no_gradï¼ˆæ¼”ç¤ºè¯„åˆ†ç‚¹ï¼‰ã€‚

Demo æé†’ï¼ˆå’Œè¯„åˆ†ç‚¹å¯¹é½ï¼‰

æ¼”ç¤ºæ—¶ï¼š

æ‰“å¼€ä»£ç ä¸è¾“å‡ºï¼›è¯´æ˜ PyTorch/TF åœ¨ä¸»è¦ç»„ä»¶é‡Œåšäº†å¹¶è¡Œè®¡ç®—ï¼ˆvectorised + maskï¼‰ã€‚

æ‰“å¼€ä½ çš„ GitHub ä»“åº“é¡µé¢ã€‚

å³ä½¿é€‰äº†â€œå¯è§†åŒ–è·¯çº¿â€ï¼Œä¹ŸåŠ¡å¿…ä¿ç•™/å±•ç¤ºä½ çš„ prompts è®°å½•ï¼›åªç”¨ä¸€ä¸ª prompt ä¼šè¢«æ‰£åˆ†ã€‚

å°ç»“

â€œç»´æ•° æˆ– å¯è§†åŒ–â€æ˜¯äºŒé€‰ä¸€ï¼›åšå¯è§†åŒ–å®Œå…¨å¯è¡Œã€‚

ä½†è¦åšæˆå®è´¨æ€§åˆ†æï¼šè‡³å°‘ 3 ä¸ªäº’è¡¥çš„å¯è§†åŒ–ç»´åº¦ + ç®€çŸ­æ–‡å­—è§£é‡Š + README å›¾ã€‚

ä¸Šé¢çš„ä»£ç æ”¹åŠ¨å¾ˆå°‘ã€äº§å‡ºç›´è§‚ï¼Œèƒ½ç¨³ç¨³å¯¹ä¸Šâ€œImportant Notesâ€å’Œâ€œDemonstrationâ€çš„è¦æ±‚

Q4:
P:
ä¸ºä»€ä¹ˆæ­¥æ•°è¶Šå°‘ï¼Œè¶Šäº®
A:
å› ä¸ºæˆ‘ä»¬åœ¨å¯è§†åŒ–é‡Œç”¨çš„æ˜¯è¿™æ ·ä¸€æ¡äº®åº¦æ˜ å°„ï¼š

shade
â€…â€Š
=
â€…â€Š
(
iters
+
ğœ€
)
âˆ’
ğ›¾
(
ğ›¾
>
0
)
shade=(iters+Îµ)
âˆ’Î³
(Î³>0)

itersï¼šè¯¥åƒç´ æ”¶æ•›æ‰€ç”¨çš„è¿­ä»£æ­¥æ•°ï¼ˆæ­¥æ•°è¶Šå°‘ = æ”¶æ•›è¶Šå¿«ï¼‰ã€‚

shadeï¼šç”¨äºä¹˜åˆ°é¢œè‰²ä¸Šçš„äº®åº¦ï¼ˆå€¼è¶Šå¤§è¶Šäº®ï¼‰ã€‚

âˆ’
ğ›¾
âˆ’Î³ æ¬¡å¹‚æ˜¯ä¸€ä¸ªå•è°ƒé€’å‡å‡½æ•°ï¼šæ­¥æ•°è¶Šå¤§ï¼Œshade è¶Šå° â†’ è¶Šæš—ï¼›æ­¥æ•°è¶Šå°ï¼Œshade è¶Šå¤§ â†’ è¶Šäº®ã€‚

ç›´è§‰ï¼šæˆ‘ä»¬æƒ³â€œå¿«æ”¶æ•› = äº®ã€æ…¢æ”¶æ•› = æš—â€ï¼Œè¿™æ ·å¸å¼•åŸŸï¼ˆbasinï¼‰å†…éƒ¨é€šå¸¸ä¸€ç‰‡æ˜äº®ã€è¾¹ç•Œå› ä¸ºéœ€è¦æ›´å¤šæ­¥æ•°è€Œæ›´æš—ï¼Œè¾¹ç•ŒèŠ±çº¹ä¼šå¾ˆæ¸…æ¥šã€‚

æ•°å€¼ç›´è§‚ï¼ˆä¸¾ä¾‹ï¼Œå– 
ğ›¾
=
0.75
Î³=0.75ï¼‰
iters	shade = iters^-0.75	äº®åº¦æ„Ÿå—
1	1.00	éå¸¸äº®
2	â‰ˆ 0.59	äº®
4	â‰ˆ 0.35	ä¸­ç­‰
8	â‰ˆ 0.21	åæš—
16	â‰ˆ 0.12	æ›´æš—

å¯ä»¥çœ‹åˆ°ï¼Œæ­¥æ•°ç¿»å€äº®åº¦å¤§çº¦ä¹˜ä»¥ 
2
âˆ’
0.75
â‰ˆ
0.59
2
âˆ’0.75
â‰ˆ0.59ï¼Œæ‰€ä»¥è¶Šæ…¢æ”¶æ•›è¶Šæš—ã€‚

ä¸ºä»€ä¹ˆä¸ç›´æ¥çº¿æ€§æ˜ å°„ï¼Ÿ

è¿­ä»£æ­¥æ•°åˆ†å¸ƒå¾€å¾€æä¸å‡åŒ€ï¼ˆå¾ˆå¤šç‚¹å¾ˆå¿«æ”¶æ•›ï¼Œå°‘æ•°ç‚¹ç‰¹åˆ«æ…¢ï¼‰ã€‚ç”¨å¹‚å‡½æ•°ï¼ˆæˆ–å¯¹æ•°/æŒ‡æ•°ï¼‰èƒ½å‹ç¼©åŠ¨æ€èŒƒå›´ï¼Œè®©è¾¹ç•Œä¸å†…éƒ¨éƒ½çœ‹å¾—æ¸…ã€‚

ğ›¾
Î³ æ˜¯å¯¹æ¯”åº¦æ§åˆ¶ï¼š

ğ›¾
Î³ å¤§ä¸€äº› â†’ æš—å¾—æ›´å¿«ï¼Œè¾¹ç•Œæ›´â€œé»‘â€ï¼Œå¯¹æ¯”å¼ºï¼›

ğ›¾
Î³ å°ä¸€äº› â†’ æ›²çº¿æ›´å¹³ç¼“ï¼Œäº®æš—å·®å‡å°ã€‚

ä½ å¯ä»¥æŠŠè¿™è¡Œæ”¹ç€ç©ï¼š

shade = (iters.astype(np.float32) + 1e-3)**(-gamma)  # gamma å¯è°ƒ

ä¹Ÿå¯ä»¥åè¿‡æ¥ç”»ï¼ˆæŒ‰éœ€æ±‚ï¼‰

å¦‚æœä½ æ›´å–œæ¬¢â€œæ…¢æ”¶æ•› = äº®ã€å¿«æ”¶æ•› = æš—â€ï¼Œåªè¦æŠŠæ˜ å°„åè¿‡æ¥å³å¯ï¼Œä¾‹å¦‚ï¼š

# çº¿æ€§å½’ä¸€åŒ–åå– 1 - normï¼šæ­¥æ•°è¶Šå¤šè¶Šäº®
m, M = iters.min(), iters.max()
norm  = (iters - m) / (M - m + 1e-9)
shade = norm**gamma        # æˆ– 1 - (1 - norm)**gamma ç­‰å˜ä½“


æˆ–è€…ç”¨æŒ‡æ•°è¡°å‡ï¼š

shade = np.exp(-alpha * iters)  # alpha æ§åˆ¶è¡°å‡é€Ÿåº¦

æ€»ç»“

æˆ‘ä»¬æœ‰æ„æŠŠâ€œæ­¥æ•°è¶Šå°‘ â†’ è¶Šäº®â€æ¥è¡¨è¾¾â€œæ”¶æ•›æ›´å¿«â€ï¼›

è¿™æ ·basin å†…éƒ¨é€šå¸¸äº®ä¸”å‡åŒ€ï¼Œbasin è¾¹ç•Œï¼ˆæ”¶æ•›æ…¢/æ··æ²Œï¼‰å‘ˆç°æš—è‰²èŠ±çº¹ï¼›

ğ›¾
Î³ æ˜¯ä½ çš„â€œå¯¹æ¯”åº¦æ—‹é’®â€ï¼ŒæŒ‰è§†è§‰éœ€è¦è°ƒæ•´å³å¯ã€‚